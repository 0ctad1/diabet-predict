# Diabetes Prediction Project

# Description

This project predicts the presence of diabetes based on patients’ medical features using Logistic Regression, Random Forest, and XGBoost.

# The project demonstrates:

Data preparation and preprocessing

Model training and evaluation

Comparison of model performance

Feature importance analysis

# Dataset

Source: Pima Indians Diabetes Dataset

Number of features: 8

Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DiabetesPedigreeFunction, Age

Target variable: Outcome (1 — diabetes, 0 — no diabetes)

# Models

Logistic Regression — simple and interpretable

Random Forest — ensemble of trees, resistant to overfitting

XGBoost — gradient boosting, high accuracy

# Metrics

Accuracy — overall correctness of the model

ROC-AUC — model’s ability to distinguish classes

Confusion Matrix — distribution of predictions across classes


# Results
This shows the models to die, and we can see that the best model is Random Forest

<img width="550" height="81" alt="image" src="https://github.com/user-attachments/assets/885c30ec-4677-427a-910a-876287b9e9e4" />



Here we can see for each model our "Top 5 Feature Importance Comparison"

<img width="1015" height="547" alt="image" src="https://github.com/user-attachments/assets/054bed26-ebcf-431e-8967-8826dea7508d" />

